---
title: "Generalised Linear Models"
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
    
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(learnr)
library(tidyverse)
library(gradethis)
library(plotly) #interactive plots
library(rcompanion)
library(lme4)

### INSTALLING LEARNR AND GRADETHIS FROM GITHUB ###
#devtools::install_github("rstudio/learnr")
#devtools::install_github("rstudio-education/gradethis")

library(gradethis) #quiz/exercise questions
gradethis_setup() #quiz/exercise questions

load("GLM.RData")
load("learnSpendSES.RData")
```
## Introduction

### **What will this tutorial tell me?**

In this section we will outline how to use linear models to analyse the PISA data. 
In statistics, linear regression is a linear approach to modelling the relationship between a variable and one or more explanatory variables (also called dependent and independent variables). The case of one explanatory variable is called simple linear regression; for more than one, the process is called multiple linear regression.

In linear regression, the relationships are modeled using linear predictor functions whose unknown model parameters are estimated from the data that have been collected. 

In this section, we will briefly cover general linear models before progressing to generalised linear models. Once we have looked at general and generalised linear models, we will look at Linear Mixed Models before finally covering Generalised Linear Mixed Models. By the end of this section you should have a solid grasp of the key concepts required to create your own models to analyse your data. 


### **Sample PISA Data**

To illustrate the concept, we will choose three plausibly related variables with standardised socres from the PISA dataset: 

  * `Spending`: time spent in the classroom.
  * `Learning`: the amount of spending on education by each of 70 different countries across    the world.  
  * `SES`: the socio economical status by country.

To give you an idea of what this looks like, the first few countries in the data are shown below:

```{r secret-"learn_spend_data.csv", echo=FALSE}
knitr::kable(head(learnSpendSES_data))
```

<p>&nbsp;</p> 


### **Visualising the Data**

Again, we will start by visualising our data with a scatterplot so that we become familiar with the datapoints. The plots in this section are interactive thanks to the `ggplotly` function, and you can hover over the points to view the country name. The larger the point size, the greater the SES.


```{r visualise PCA, echo=TRUE, message=FALSE, warning=FALSE}
#Raw spending,learning and SES data
ggplotly(
  ggplot(learnSpendSES_data, aes(Learning, Spending, group = Country)) +
  geom_point(aes(color = SES, size =SES)) +
  xlab('Average of time spent in the classroom') +
  ylab('Amount of spending on education')+
  theme(legend.position="none"),
  tooltip = "group")
  
```

<p>&nbsp;</p>


A good point to start when beginning an analysis is to visualize the data. In this case we can begin by visualizing the distribution of the scores (the dependent variable in our data). In order to do this we can create a histogram. 


```{r histogram of scores, echo=FALSE}
ggplot(learnSpendSES_data, aes(ReadingScore)) + 
  geom_histogram(binwidth = 25, color = 'white', fill = 'lightblue') +
  theme_minimal()
```

From the histogram it appears that the data is slightly negatively skewed. This would suggest that the use of a standard linear model may not be the best approach. Despite this we can still fit one and see how it deals with the data.

<p>&nbsp;</p>


## The Basics

### **An introduction to regression**


Regression analysis is a way of predicting an outcome variable *Y*  from one predictor variable *X<sub>1</sub>* (simple regression) or several predictor variables *X<sub>1</sub>*, *X<sub>2</sub>*... (multiple regression)  using the folowing general equation: 

    outcome = (model) + error

This means that we predict the outcome by whatever model we fit to the data plus some kind of error. In regression, the model we fit is linear, which means that we summarize a data set with a straight line. In the ecuation, we will replace the word model by things that define the line that we fit to the data. The mathematical equation to estimate the value of the response *Y* when only the *X* is known can be generalized as follows: 

  *Y* = (*b*<sub>0</sub> + *b*<sub>1</sub> *X*<sub>i</sub>) + E



  
In this equation:

  * *Y* is the outcome that we want to predict
  * *X*<sub>i</sub> is the participants score on the predictor variable. 
  * Parameter *b*<sub>0</sub> is the intercept and *b*<sub>1</sub> is the slope. Both are known as the **regression coefficients** and we will refer at them in the next sections. The common approach to find the line which is as close as possible to our data points, is the least squares criterion. 
  * E is a residual term, which represents the difference between the score predicted by the line for participant *i* and the score that participant *i* actually obtained. From this term is important to understand that it represents the fact that our model will not fit the data collected perfectly. 

Multiple regression it is basically the same as for simple regression except that for every extra predictor you include, you have to add a coefficient. Each predictor variable has its own coefficient, and the outcome variable is predicted from a combination of all the variables multiplied by their respective coefficients plus a residual term. 

  *Y* = (*b*<sub>0</sub> + *b*<sub>1</sub> *X*<sub>1</sub><sub>i</sub> + *b*<sub>2</sub> *X*<sub>2</sub><sub>i</sub> +*b*<sub>n</sub> *X*<sub>n</sub><sub>i</sub>) + E

With this equation, we seek to find the linear combination of predictors that correlate maximally with the outcome variable. Therefore, when we refer to the regression model in multiple regression, we are talking about a model in the form of this last equation. 


### **Previous Graphical Analysis**

The graphical representation of our variables can help visualize any linear relationships between the dependent and the independent variables. As we have multiple predictor variables, a scatter plot is drawn for each one of them against the outcome variable. 

We can visualize the linear relationship between the predictor variables (`Spending`,`Learning`, `SES`) and the response variable (`ReadingScore`) through a scatter plot using `ggplot` function:

```{r linear-regression-plot1, echo= TRUE}

ggplot(learnSpendSES_data, aes(x=Spending, y=ReadingScore)) +
    geom_point()+ #scatterplot for Spending
    geom_smooth(method=lm)   # Add linear regression line
ggplot(learnSpendSES_data, aes(x=Learning, y=ReadingScore)) +
    geom_point()+ #scatterplot for Learning
    geom_smooth(method=lm)   # Add linear regression line

```

The scatter plots along with the smoothing line above suggest a linearly increasing relationship between `Spending`and `ReadingScore`variables, and a linearly decreasing relationship between `Learning`and `ReadingScore` variables. 

Could you do it for our variable `SES`? Use the function ggplot and follow the same structure of the previous scatterplot. 

```{r linear-regression-plot3, exercise = TRUE, message = FALSE}
ggplot( , aes(x=  , y=  ))+ 
  geom_point()+ 
  geom_smooth(method= )
```

```{r linear-regression-plot3-hint-1}
## variables ##
#Use the dataset learnSpendSES_data with Learning as predictor and ReadingScore as outcome variable
# Then, add linear regression line
```

```{r linear-regression-plot3-solution}
#create the plot
ggplot(learnSpendSES_data, aes(x=SES, y=ReadingScore)) +
    geom_point()+    
    geom_smooth(method=lm)
```

We can see that the variable SES does not appear to have a linear distribution since we can see a point cloud where it look as if there are two subsets. 


## Simple linear regression model

Now that we have visualized the linear relationship in the scatter plot, lets see the syntax for building the linear model. For our linear model we will use the `lm()` function. Form our data set `learnSpendSES`, our `ReadingScore` column will be our dependent variable, whilst the `Spending` will be used as our independent variables (predictors). 


```{r simple linear model, message = FALSE, echo=TRUE, eval=TRUE}
# Use the lm function to create a linear model
LM_model_one <- lm(ReadingScore ~ Spending, data = learnSpendSES_data)
summary(LM_model_one)
```


### **What a simple regression summary tell us?**

Beginning from the bottom we find: 

    F-statistic: 16.46 on 1 and 45 DF,  p-value: 0.0001951

This part of the output tells us the F-ratio and the associated significance value of that F-ratio. For these data is significant at *p* < .001, therefore, we can conclude that our regression model is significantly predicting ReadingScores. 

    Multiple R-squared:  0.2678,	Adjusted R-squared:  0.2516 
R-square value describes the overall model (so it tells us whether the model is successful in predicting `ReadingScore`). The value of R-square is a measure of how much of the variability in the outcome is accounted for by the predictors. For our first model this value is .267 which means that `Spending` accounts for 26.7% of the variation in `ReadingScore`. The adjusted r-square gives us some idea of how well our model generalizes, and ideally, we would like its value to be the same, or very close to, the value of r-square.

    Coefficients:
                Estimate Std. Error t value Pr(>|t|)    
    (Intercept)  473.047      5.902  80.144  < 2e-16 ***
    Spending      24.018      5.920   4.057 0.000195 ***
    ---
    Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1  1

Coefficients contains the model parameters (the beta values) and the significance of these values. In regression equation, B<sub>0</sub> is the Y intercept and this value is the value in the Estimate column for (intercept), in brackets because it is not a real variable. We can say that B<sub>0</sub> is 473.05, and this can be interpreted as meaning that wen no `Spending` is done (when X= 0), the model predicts that 473.05 `Score` would be achieve. We can also read off the value of b1 from the row labelled `Spending` and this value represent the gradient of the regression line. It is 24.01. Although this value is the slope of the regression line, it is more useful to think of this value as representing the change in the outcome associated with a unit change in the predictor. Therefore, if our predictor variable `Spending` is increased by one unit, our model predicts that `Score` will increase 24.01. We also see that the t-test tells us whether the b-value is different from 0. For this variable, we can conclude that the `Spending` makes a significant contribution (p<.001) to predicting `ReadingScore`.


#### Exercise

Now it is your turn to use`lm()`function for modelling the relationship between `Learning` and `ReadingScore` from `learnSpendSES_data`. 

```{r simple-linear-regression, exercise = TRUE, message = FALSE}
#Create the linear model from dataset learnSpendSES_data
LM_model_two <- lm(~ ,data = ) 
#Ask for the summary result of your model
summary()
```

```{r simple-linear-regression-hint-1}
## variables ##
# The first variable you have to write is our dependent and the second, our independent variable
# For visualize the result write the name of our model
# Warning! next hint shows full solution. Try something before it!
```

```{r simple-linear-regression-hint-2}
## variables ##
# our dependent variable is ReadingScore and our independent variable is Learning
```

```{r simple-linear-regression-solution}
#create biplot
LM_model_two <- lm(ReadingScore ~ Learning, data = learnSpendSES_data)
summary(LM_model_two)
```

As we can see, the coefficient for `Learning`is negative, indicating that it has a negative association with our outcome variable `ReadingScore`.


```{r quiz_simple_linear_model, echo = FALSE}
quiz(question ("We can now compare the predictor value of our two regression models. If we look at the R-square statistics from each model, what statement is correct?",
              answer("Both models are significant so both are good predictors in the same degree for our outcome variable."),
              answer("Adjusted R-squared is higher for`Spending` (0.25) than for `Learning` (0.08), so it means that Spending explain a higher proportion of the variability in ReadingScore.", correct = TRUE),
              answer("`Spending` is a better predictor than `Learning` because Learning is negatively associated with ' ReadingLearning'  "),
              answer("The signification for the coefficients is higher for`Spending` than for `Learning`, so it means that Spending explain a higher proportion of the variability in ReadingScore"),
              allow_retry = TRUE, 
              correct = "Correct! The adjusted R-square for Spending is 0.25 which means that Spending account for 25% of the variation in ReadingScore. The 75% of the variation in ReadingScore can not be explained by Spending alone, therefore, there must be other variables that have an influence also."
)
  )
```


## Multiple linear regression model

When the two predictors, `Spending` and `Learning` are included in our regression model, the value of R-square (how much of the variability in the outcome is accounted for by the predictors) will increase? We will use`lm()` with `learnSpendSES_data` function for check it.


```{r multiple linear model, message = FALSE, echo=TRUE, eval=TRUE}
# Use the lm function to create a linear model
LM_model_three <- lm(ReadingScore ~ Spending + Learning, data = learnSpendSES_data)
summary(LM_model_three)
```
<p>&nbsp;</p>


The adjusted R-square in multiple regression model has increase from 0.25 to 0.27, but only `Spending` variable made a significant contribution. We can see what happen when the interaction of this two factors is included: 

```{r multiple linear model step 2, message = FALSE, echo=TRUE, eval=TRUE}
# Use the lm function to create a linear model
LM_mod_four <- lm(ReadingScore ~ Spending * Learning, data = learnSpendSES_data)
summary(LM_mod_four)
```

<p>&nbsp;</p>

The output from the results show that `Spending`and `Learning`interaction is not a significant predictor. At this point, you may be dissapointed that we did not find a better model to explain our outcome variable `ReadingScore`and you may want to explore what would happen if we try to add the variable `SES`to our multiple linear model. We can try!

```{r multiple_linear_model_interaction, exercise = TRUE, message = FALSE}
#Create the linear model from dataset learnSpendSES_data
LM_model_five <- lm(   ~  *  *  * ,data = ) 
#Ask for the summary result of your model
summary()
```

```{r multiple-linear-model-interaction-hint-1}
## variables ##
# The first variable you have to write is our dependent variable and after that, our three independent variables separated by *
# Add the three possible interactions between our independent variables separated by *
```

```{r multiple-linear-model-interaction-hint-2}
## variables ##
# For visualize the result write the name of our model: LM_model_three 
# Warning! next hint shows full solution. Try something before it!
```

```{r multiple-linear-model-interaction-solution}
#create biplot
LM_model_five <- lm(ReadingScore ~ Spending * Learning * SES, data = learnSpendSES_data)
summary(LM_model_five)
```


For the models with Spending and Learning as predictor variables, the value of adjusted R-square was 0.25. When we included SES, this value increases to 0.51. That means that the last model, where Spending and the interaction of Spending and SES were significant, accounts for 51% of the variation in Reading Scores. If we look at the coefficients, we can see that `Spending` has a positive association with `ReadingLearning`, and that the interaction between `spending` and `SES` has a negative relationship. This negative interaction is not easy to interpret. 

The variable `SES` did not appear to have a linear association with `ReadingScore`, based on the scatter plot visualization in the previous section. And our outcome variable `ReadingScore` was lightly negatively skeewed. In the next section, we will learn other statistics analysis to deal with data with different types of distributions. 

## Generalized Linear Models

An alternative approach to analyzing the PISA data could be to use a generalized linear model. A generalized linear model is similar to a general linear model, except some of the constraints are relaxed. This typically makes it better when dealing with data that is not normally distributed, such as is the case with the PISA data.

There are different family arguments that can be made when using a generalized linear model. These different families allow us to deal with data with different types of distributions. Family distributions include Gaussian (which is the bases of the linear model and ideal for normally distributed data), Binomial (which is useful when dealing with a binomial distribution), and Gamma (which is useful when there is skewed data). These are just a few of the families that can be applied when using a generalized linear model. Since we are dealing with data that is negatively skewed we will use the Gamma family in our example. If you are not very familiar with this distribution, it looks like this: 

```{r gamma distribution, echo=TRUE, eval=TRUE}

# R program to plot gamma distribution
  
# Specify x-values for gamma function
x_pgamma <- seq(0, 2, by = 0.04)   
  
# Apply pgamma function
y_pgamma <- pgamma(x_pgamma, shape = 6) 
  
# Plot pgamma values
plot(y_pgamma)
```

The code for using the glm is very similar to the code needed when creating a linear model. The only difference is now at the end of the code we specify the family and link arguments. Link arguments allow us to apply transformations to the model parameters and also determines the way the model coefficients are interpreted. Changing the link function can, in some cases, result in a better fitting model. There are many different link arguments for each family but for now we will just use the standard identity link. 

```{r generalised linear model, echo=TRUE, eval=TRUE}
# Use the glm function to create a generalised linear model
GLM_model <- glm(ReadingScore ~ Spending * Learning * SES,
               data = learnSpendSES_data, 
# specify the family as gamma with an identity link
               family= Gamma(link = "identity"))
# Get the output from the generalised linear model
summary(GLM_model)
```


<p>&nbsp;</p>

Here we can see that the output presented when we use the glm function is very similar to the output when we use the lm function. One of the main differences is to do with the goodness of fit statistic presented in the two outputs. when we use the lm function the goodness of fit statistic is given as the adjusted R-squared. with the glm function, the goodness of fit statistic given is the *Akaike Information Criteria* (AIC) score.  

From the output we can see that there are differences in the significance values in the glm output compared to the lm output. In the glm output we now find that two are significant main effects of `Spending` and `Learning`. There is now significant two way interactions between `Spending` and `Learning` and between `Spending`and `SES`. Significant three way interactions were also found among `Spending`, `Learning` and `SES`. 

<p>&nbsp;</p>

### **Model comparison**

Now that we have fitted a generalized linear model to the data we can check to see if it really fits the data better than our original linear model. One of the simplest ways, is to compare the models is to look at the Akaike Information Criterion (AIC). This is a goodness of fit statistic which takes into account how well a model explains the data and adds a penalty for model complexity. AIC scores can be used to compare the goodness of fit of different models. The general rule when comparing models using AIC is that the model with the lowest AIC value fits the data better. The AIC is quite arbitrary however, as there are no set guidelines for using it. We can obtain the AIC value by using the `AIC()` function. 
```{r simple AICs, echo = TRUE}
# run the AIC for the linear model with Spending
lm_AIC <- AIC(LM_model_one)
lm_AIC

# run the AIC for the linear model with Spending and Learning 
lm_AIC <- AIC(LM_model_three)
lm_AIC
# run the AIC for the linear model with Spending, Learning and its interaction
lm_AIC <- AIC(LM_mod_four)
lm_AIC
# run the AIC for the linear model with Spending, Learning and SES and their interaction
lm_AIC <- AIC(LM_model_five)
lm_AIC
# Run the AIC for the generalised linear model
glm_AIC <- AIC(GLM_mod)
glm_AIC
```
<p>&nbsp;</p>

From looking at our AIC values we find a rather interesting result. It appears that the Linear model has a lower AIC value than the Generalized linear model. In this case it would suggest that using a standard linear model would have a better fit than using using the gamma family with an identity link function. 

<p>&nbsp;</p>

### **Simple model exercises**

```{r LM_Questions, echo=FALSE}
quiz(question("What does the family argument relate to?",
    answer("The type of optimizer used"),
    answer("The distribution of the independent variable"),
    answer("The distribution of the dependent variable", correct = TRUE),
    answer("The type of optimizer we want to use"), 
    allow_retry = TRUE, 
    correct = "Correct! The family argument lets us add different family classes relating to the distribution of our dependent variable, i.e. The family argument relates to the distribution of the thing we are trying to predict"),
    question("What does the link function do?", 
             answer("Applies a transformation to the model parameters", correct = TRUE),
             answer("Transforms the data"),
             answer("Makes the model fit better"),
             answer("Allows us to deal with different distributions of data"), 
             allow_retry = TRUE, 
             correct = "Correct! Using link functions allows us to transform the model parameters."),
    question("True or False: When comparing two models using AIC values, the model with the highest AIC fits the data better", 
             answer("True"), 
             answer("False", correct = TRUE), 
             allow_retry = TRUE, 
             correct = "Correct! The lower the AIC value, the better a model fits the data")
    )
```

<p>&nbsp;</p>
<p>&nbsp;</p>

## More complex Models

Now that we have gone through simple model types we will look at more complex models. The next section will look at Linear Mixed Models (LMMs) and Generalised Linear Mixed Models (GLMMs). These two model types expand on the ideas from the simple models shown in the previous section but add additional options to help fit the data better. This tutorial will provide a brief overview of more complex models, however a more detailed explanation is given in a paper written by Barr et al., (2013). 

One of the ways in which LMMs and GLMMs expand on the previous models covered in this tutorial is through the introduction of fixed and random effects. These can be introduced by classifying our independent variables as fixed or random effects. When we refer to a variable as a fixed effect, we assume that this variable remains constant across replications. In most cases the fixed effects that we select for our model are the main predictors that we wish to use to predict our independent variable. In the models that we are fitting to the PISA data, we assume that the Spending and the Learning variables are fixed effects as we assume that these would remain relatively constant among replications. 
 
Random effects refer to the sources of random variation that may occur in our model. Random variation is the variation that occurs in our model even when we have controlled for everything. One major source of random variation within psychological experiments can be found with the participants as some participants may be better suited to some tasks than others. Another key source of variance in psychological experiments is the items used as some may be more effective for an experiment than others. This random variance means that scores of participants and on items may fluctuate in a random pattern. By using LMMs and GLMMs we can assign specific variables that may be sources of random variance as random effects. By doing this we are bale to account for the random variance that occurs within our models which in turn can help to make our model fit the data better than using more simple modelling techniques. 

By assigning random effects in our models we can add random slopes and intercepts which help us to model the data better. By adding in random slopes we are allowing our fixed effects to vary based on each of the items within our random effects. Random intercepts allow for a variation in the scores obtained for each of the items within the random effects.

Suppose we ran a study in which 10 participants were asked to complete a stroop task. We could assign the students in the study as a random effect as some would naturally perform better than others. We could therefore add a random slope for each of the 10 participants. By doing this, in theory, we should create a better fitting model of the data as we are accounting for the performance of each individual participant on the task. We could also add in random intercepts for each of the 10 participants which would in turn allow us to account for the variance in the individual scores of each of the participants. By doing this we should therefore create a better fitting model as we are now accounting for the random variance that occurs due to the differences in abilities of the participants.

With the PISA data we could assume that the variable `country` is a random variable. We could assume that the different countries would create a random variance due to factors that are not controlled for within our models. We could also assume that `Item` is a random variable as we could assume that some items may be more effective than others in measuring the scores in each of the predictor variables. 

<p>&nbsp;</p>

Now that we have discussed the key differences between the simple linear models and the more complex models, let's work through an example. The next section will go through the steps involved in running a Linear Mixed Model on the PISA data. 


<p>&nbsp;</p>

### **Linear Mixed Effect Model**

Setting up and running a linear mixed model (LMMs) is very similar to setting up and running a standard linear model. There are some key differences though. Base R does not have a function that can effectively deal with LMMs and so we have to use a different package. The package that is most commonly used to run LMMs is known as the `lme4` package. Once that package has been loaded in we can begin to create LMMs. The function within the lme4 package that is required is known as the `lmer()` function. Once we have selected this function we then have to tell it what model we want it to run. This is done in a similar way to that of the `lm()` function. We start by specifying the dependent variable, then we add in our predictors and finish by specifying our data. The differences appear when we want to add in our random effects. In order to add random effects we have to use the following input `(1|random effect)`. If we want to specify in our model that the random effect is interacting with our predictors, i.e we have within subjects interactions between certain fixed and random effects, then we can do it like this: `(1 + predictor|random effect)`.

In our example below, we have selected the same variables as before in the standard linear model for our dependent variable and our predictors. This time however, we have set the Country, Item and the ID as random effects. For the random effects we are taking into account the interaction between the random effect of Country and the fixed effect of Spending and Learning. We are also taking into account the interaction between the random effect of ID and the Economics Social and Cultural status; and the Attitudes towards education. 

```{r Linear mixed effect model, echo=TRUE, eval=FALSE}
# Use lmer to run a linear mixed model
LMM_mod <- lmer(Score ~ Spending * Learning * ESCS * ATTLNACT +
# Use the (1 + X|random variable) strucutre to add in the random effects
                   (1 + Spending * Learning | Country) +
                   (1 + ESCS * ATTLNACT | ID) + 
                   (1|Item),
                 data = read_data)
# Get a summary of the output
summary(LMM_mod)
```
```{r secret Linear mixed effect model, echo=FALSE}
summary(LMM_mod)
```
<p>&nbsp;</p>

Here we can see the output from the LMM. At the top of this output we can see that there is an error telling us: `boundary(singular) fit: see ?isSingular`. Although at first this may be alarming, it is quite alright. All this is telling us is that one or more of the correlations for the random effects is very close to being 0. If we look at the correlations we can see that this is true. For the random effect of country, the interaction of Spending and Learning shows a correlation of 0.01. This error is okay so we can continue with analyzing the data.

If an error appeared stating that our model failed to converge however, this would be a problem. Although we would receive an output, we could not use it. There are many reasons that can cause a model to not converge properly. These include model mispessification, strong imbalances in the design, and having too few data to estimate the parameters. Although there are no generally accepted methods to dealing with this error, there are some methods that can be used. The optimizer settings for the model could be altered, the model could be simplified slightly or more data could be collected. 

Within the output the main focus for the analysis is the fixed effects output. One major thing that you may notice here is that there are not any p-values. This is okay. The creator of the lmer function decided not to include any p-values in the output of the lmer function. The author argued that p-values could be misleading and that the use of p-values can sometimes create problems in research, so they decided that the best option would be not to include them in the output of the lmer function. Instead we just get the Estimate, Std. Error and the t-value. There are other functions however, that can give us the p-value for our results. 

<p>&nbsp;</p>

### **Generalized Linear Mixed Models**

We could also fit a generalized linear mixed model to look at the data. These work in exactly the same way as a generalized linear model, in that they allow us to apply different family classes in an attempt to fit a model to data that is not normally distributed. With a generalized linear mixed model, we can take the same formula as was used in our linear mixed model, but add different family classes and link functions in an attempt to fit the data better. 

Creating a generalized linear mixed model in R is very similar to that of creating a linear mixed model. This time however, instead of using the `lmer()` function form the `lme4` package we will use the `glmer()` function. The way fixed and random effects are added are identical between the two functions. With the `glmer()` function however, we can now specify families and link functions, just as was done with the `glm()` function. 

In our example we will use the same model structure as in the linear mixed model by keeping the fixed and random effects the same. We will include the Gamma family with an identity link function, making it similar to what was done in the generalized linear model example in the previous section. In our code we have changed the default optimizer to the 'bobyqa' optimizer. Typically the default optimizer works well, however, in this case it was found that the 'bobyqa' optimizer helped in making the model converge.

```{r generalised linear mixed effect model, eval = FALSE, echo=TRUE}
# Use glmer to create a generalised linear mixed model
GLMM_mod <- glmer(Score ~ Spending * Learning * ESCS * ATTLNACT +
# Specify the random effetcs and thier interactions
                     (1 + Spending * Learning | Country) +
                     (1 + ESCS * ATTLNACT | ID) +
                     (1 | Item),
                   data = read_data,
# sepcify the family you want to use and the link function
                   family = Gamma(identity),
# Change the optimizer used in the example
                   control = glmerControl(optimizer = c("bobyqa")))
# Get the output of the analysis
summary(GLMM_mod)
```
```{r secret GLMM, echo = FALSE}
summary(GLMM_mod)
```
<p>&nbsp;</p>

Here we can see that the output from the `glmer()` function is similar but not identical to that of the lmer output. One of the major differences that you will notice this time is the presence of p-values in the fixed effect output. With the p-values we are able to identify which main effects and interactions were significant. From this output we can see that there was a significant main effect of spending and a significant main effect of economic, social and cultural status on the scores. 

<p>&nbsp;</p>

### **Model comparison**

As was done with the general linear model and the generalized linear model, we can compare the generalized linear mixed model and the linear mixed model to see which of these two fit the data better. In order to do this we will again use the AIC values.

```{r LMM and GLMM model comparision, echo=TRUE}
# Get the AIC for the LMM_read
LMM_AIC <- AIC(LMM_mod)
LMM_AIC
#Get the AIC for GLMM_read 
GLMM_AIC <- AIC(GLMM_mod)
GLMM_AIC
```
<p>&nbsp;</p>

From the output of the AIC values we can see that the AIC value for the generalized linear mixed model with the gamma family and link identity has a lower AIC value (AIC = 38739) compared to the AIC value of the linear mixed model (AIC = 39523). Since the generalized linear mixed model has a lower AIC value we can conclude that this model fits the data better. we can also compare this to the AIC values from the linear mixed model (AIC = 47481) and the generalized linear model (AIC = 47636). Again we can see that the AIC value for the generalized linear mixed model is lower than the AIC values for all the model we have created in this tutorial. We can therefore conclude that in this case, the generalized linear mixed model using the gamma family with an identity link has the best fit of the data. 

<p>&nbsp;</p>

### **Complex model Exercise**


```{r quiz, echo = FALSE}
quiz(question("What is a fixed effect?",
              answer("A dependent variable that is assumed to change when the experiment is replicated"),
              answer("A predictor variable that is assumed to remain constant when the experiment is replicated", correct = TRUE),
              answer(" A predictor variable that is assumed to change when the experiment is replicated"),
              answer("A dependent variable that is assumed to remain constant when the experiment is replicated"),
              allow_retry = TRUE, 
              correct = "Correct! A fixed effect is a predictor variable that is assumed to remain constant when the experiment is replicated. These are typically the predictor variables of interest in our model"),
     question("What is the purpose of adding a random slope?",
              answer("It allows us to fit slopes to account for the variance of random effects", correct = TRUE), 
              answer("It allows us to fit slopes to account for the variance of fixed effects"), 
              answer("It allows us to see the interaction between random effects"),
              answer("It allows us to see the interaction between the fixed factors and random effects"), 
              allow_retry = TRUE, 
              correct = "Correct! BY adding random slopes we can account for the variance of the random factors"),
  question("Which package contains functions for running a linear mixed model?",
    answer("base"),
    answer("stats"),
    answer("lme4", correct = TRUE),
    answer("car"), 
    allow_retry = TRUE, 
    correct = "Correct! The lme4 package can be used to run both linear mixed models and generalized linear mixed models"
  ), 
  question("Which function is used to run a generalized linear mixed model?", 
           answer("lm"),
           answer("lmer"), 
           answer("glm"), 
           answer("glmer", correct = TRUE), 
           allow_retry = TRUE,
           correct = "Correct! the glmer function is used to create a generalized linear mixed model"),
  question("Which of these is NOT a reason that a model may fail to converge?",
           answer("The model parameters were misspecified"),
           answer("The data set is too large for R to fit the model", correct = TRUE),
           answer("There are strong imbalances in the design"),
           answer("There are too few data points"),
           allow_retry = TRUE, 
           correct = "Correct! there are many reasons that a model fails to converge however, having too many data points is not one of them!")
)
```

Run a Generalized linear mixed model  similar to the one in the example given in this section but switch the identity link with a with a log link. Calculate the AIC of this new model and compare it to the AIC values of the previous models created throughout the tutorial. 

```{r GLMM-exercise, exercise = TRUE, exercise.eval = TRUE}

```

```{r GLMM-exercise-hint1}
# Have a look at the code in the tutorial above
```

```{r GLMM-exercise-hint2}
# Make sure you are suing the correct function 'lmer()' and are specifying the correct family argument
```

```{r GLMM-exercise-solution}
# Run the glm() function and use a log link function 
GLMM_dat <- glmer(Score ~ Spending * Learning * ESCS * ATTLNACT +
# Specify the random effetcs and thier interactions
                     (1 + Spending * Learning | Country) +
                     (1 + ESCS * ATTLNACT | ID) +
                     (1 | Item),
                   data = read_data,
# sepcify the family you want to use and the link function
                   family = Gamma(identity),
# Change the optimizer used in the example
                   control = glmerControl(optimizer = c("bobyqa")))
# Get the summary of the new model
summary(GLMM_dat)
# Find the AIC value of the model 
AIC(GLMM_dat)
```

```{r glm-exercise-error-check}
grade_code(incorrect = "Make sure you are using the correct function and arguments.", glue_incorrect = "{ .message } { .incorrect }")
```
<p>&nbsp;</p>

### **Conclusion**

In this tutorial we have covered how to sort data for analysis and how to run different types of models. Now that you have completed this tutorial you should have a basic understanding of: how to sort data for analysis, how to run linear models and generalized linear models, the basic components behind linear mixed models and generalized linear mixed models, how to run linear mixed models and generalized linear mixed models, how to compare models.

We hope this tutorial has helped you to understand how generalized linear mixed models work and how to use them in your data analysis. 
<p>&nbsp;</p>

## Coding exercises

In this section you can practice what you have learned in the tutorial. Here we would like you to firslty create a generalised linear model which fits the PISA data, using the same independent and dependent variables as were used in the tutorial. This time however we would like you to use a gamma family argumetn with a log link function. Once you have completed that we would like you to greate a Generalised linear Mixed model using the same independent and dependent variables as were used in the tutorial but use a gamma family argumetn with a log link function. 

### **Glm exercise**
Create a generalized linear model similar to the one used in the tutorial. This time however, use a log link function. Once you have created the model with the log link function, calculate the AIC value. 
```{r coding1-exercise, exercise = TRUE, exercise.eval = TRUE}

```

```{r coding1-exercise-hint1}
# Take a look at the code above to make sure you are using the correct function
```

```{r coding1-exercise-hint2}
# Are you sing the correct family and link arguments
# make sure you are using 'family = Gamma(link = "log")'
```

```{r coding1-exercise-solution}
# Run the glm() function and use a log link function 
GLM_dat <- glm(Score ~ Spending * Learning * ESCS * ATTLNACT + Item, data = read_data, family= Gamma(link = "log"))
# Get the summary of the new model
summary(GLM_dat)
# Find the AIC value of the model 
AIC(GLM_dat)
```



### **GLMM exercise**

Run a Generalized linear mixed model  similar to the one in the example given in this section but switch the identity link with a with a log link. Calculate the AIC of this new model and compare it to the AIC values of the previous models created throughout the tutorial. 

```{r coding2-exercise, exercise = TRUE, exercise.eval = TRUE}

```

```{r coding2-exercise-hint1}
# Have a look at the code in the tutorial above
```

```{r coding2-exercise-hint2}
# Make sure you are suing the correct function 'lmer()' and are specifying the correct family argument
```

```{r coding2-exercise-solution}
# Run the glm() function and use a log link function 
GLMM_dat <- glmer(Score ~ Spending * Learning * ESCS * ATTLNACT +
# Specify the random effetcs and thier interactions
                     (1 + Spending * Learning | Country) +
                     (1 + ESCS * ATTLNACT | ID) +
                     (1 | Item),
                   data = read_data,
# sepcify the family you want to use and the link function
                   family = Gamma(identity),
# Change the optimizer used in the example
                   control = glmerControl(optimizer = c("bobyqa")))
# Get the summary of the new model
summary(GLMM_dat)
# Find the AIC value of the model 
AIC(GLMM_dat)
```


<p>&nbsp;</p>
<p>&nbsp;</p>